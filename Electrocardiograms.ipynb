{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Electrocardiograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Electrocardiograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👇 Import the [`electrocardiograms.csv`](https://wagon-public-datasets.s3.amazonaws.com/Machine%20Learning%20Datasets/ML_Electrocardiograms_dataset.csv) dataset and display its first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>x_5</th>\n",
       "      <th>x_6</th>\n",
       "      <th>x_7</th>\n",
       "      <th>x_8</th>\n",
       "      <th>x_9</th>\n",
       "      <th>x_10</th>\n",
       "      <th>x_11</th>\n",
       "      <th>x_12</th>\n",
       "      <th>x_13</th>\n",
       "      <th>x_14</th>\n",
       "      <th>x_15</th>\n",
       "      <th>x_16</th>\n",
       "      <th>x_17</th>\n",
       "      <th>x_18</th>\n",
       "      <th>x_19</th>\n",
       "      <th>x_20</th>\n",
       "      <th>x_21</th>\n",
       "      <th>x_22</th>\n",
       "      <th>x_23</th>\n",
       "      <th>x_24</th>\n",
       "      <th>x_25</th>\n",
       "      <th>x_26</th>\n",
       "      <th>x_27</th>\n",
       "      <th>x_28</th>\n",
       "      <th>x_29</th>\n",
       "      <th>x_30</th>\n",
       "      <th>x_31</th>\n",
       "      <th>x_32</th>\n",
       "      <th>x_33</th>\n",
       "      <th>x_34</th>\n",
       "      <th>x_35</th>\n",
       "      <th>x_36</th>\n",
       "      <th>x_37</th>\n",
       "      <th>x_38</th>\n",
       "      <th>x_39</th>\n",
       "      <th>x_40</th>\n",
       "      <th>x_41</th>\n",
       "      <th>x_42</th>\n",
       "      <th>x_43</th>\n",
       "      <th>x_44</th>\n",
       "      <th>x_45</th>\n",
       "      <th>x_46</th>\n",
       "      <th>x_47</th>\n",
       "      <th>x_48</th>\n",
       "      <th>x_49</th>\n",
       "      <th>x_50</th>\n",
       "      <th>x_51</th>\n",
       "      <th>x_52</th>\n",
       "      <th>x_53</th>\n",
       "      <th>x_54</th>\n",
       "      <th>x_55</th>\n",
       "      <th>x_56</th>\n",
       "      <th>x_57</th>\n",
       "      <th>x_58</th>\n",
       "      <th>x_59</th>\n",
       "      <th>x_60</th>\n",
       "      <th>x_61</th>\n",
       "      <th>x_62</th>\n",
       "      <th>x_63</th>\n",
       "      <th>x_64</th>\n",
       "      <th>x_65</th>\n",
       "      <th>x_66</th>\n",
       "      <th>x_67</th>\n",
       "      <th>x_68</th>\n",
       "      <th>x_69</th>\n",
       "      <th>x_70</th>\n",
       "      <th>x_71</th>\n",
       "      <th>x_72</th>\n",
       "      <th>x_73</th>\n",
       "      <th>x_74</th>\n",
       "      <th>x_75</th>\n",
       "      <th>x_76</th>\n",
       "      <th>x_77</th>\n",
       "      <th>x_78</th>\n",
       "      <th>x_79</th>\n",
       "      <th>x_80</th>\n",
       "      <th>x_81</th>\n",
       "      <th>x_82</th>\n",
       "      <th>x_83</th>\n",
       "      <th>x_84</th>\n",
       "      <th>x_85</th>\n",
       "      <th>x_86</th>\n",
       "      <th>x_87</th>\n",
       "      <th>x_88</th>\n",
       "      <th>x_89</th>\n",
       "      <th>x_90</th>\n",
       "      <th>x_91</th>\n",
       "      <th>x_92</th>\n",
       "      <th>x_93</th>\n",
       "      <th>x_94</th>\n",
       "      <th>x_95</th>\n",
       "      <th>x_96</th>\n",
       "      <th>x_97</th>\n",
       "      <th>x_98</th>\n",
       "      <th>x_99</th>\n",
       "      <th>x_100</th>\n",
       "      <th>x_101</th>\n",
       "      <th>x_102</th>\n",
       "      <th>x_103</th>\n",
       "      <th>x_104</th>\n",
       "      <th>x_105</th>\n",
       "      <th>x_106</th>\n",
       "      <th>x_107</th>\n",
       "      <th>x_108</th>\n",
       "      <th>x_109</th>\n",
       "      <th>x_110</th>\n",
       "      <th>x_111</th>\n",
       "      <th>x_112</th>\n",
       "      <th>x_113</th>\n",
       "      <th>x_114</th>\n",
       "      <th>x_115</th>\n",
       "      <th>x_116</th>\n",
       "      <th>x_117</th>\n",
       "      <th>x_118</th>\n",
       "      <th>x_119</th>\n",
       "      <th>x_120</th>\n",
       "      <th>x_121</th>\n",
       "      <th>x_122</th>\n",
       "      <th>x_123</th>\n",
       "      <th>x_124</th>\n",
       "      <th>x_125</th>\n",
       "      <th>x_126</th>\n",
       "      <th>x_127</th>\n",
       "      <th>x_128</th>\n",
       "      <th>x_129</th>\n",
       "      <th>x_130</th>\n",
       "      <th>x_131</th>\n",
       "      <th>x_132</th>\n",
       "      <th>x_133</th>\n",
       "      <th>x_134</th>\n",
       "      <th>x_135</th>\n",
       "      <th>x_136</th>\n",
       "      <th>x_137</th>\n",
       "      <th>x_138</th>\n",
       "      <th>x_139</th>\n",
       "      <th>x_140</th>\n",
       "      <th>x_141</th>\n",
       "      <th>x_142</th>\n",
       "      <th>x_143</th>\n",
       "      <th>x_144</th>\n",
       "      <th>x_145</th>\n",
       "      <th>x_146</th>\n",
       "      <th>x_147</th>\n",
       "      <th>x_148</th>\n",
       "      <th>x_149</th>\n",
       "      <th>x_150</th>\n",
       "      <th>x_151</th>\n",
       "      <th>x_152</th>\n",
       "      <th>x_153</th>\n",
       "      <th>x_154</th>\n",
       "      <th>x_155</th>\n",
       "      <th>x_156</th>\n",
       "      <th>x_157</th>\n",
       "      <th>x_158</th>\n",
       "      <th>x_159</th>\n",
       "      <th>x_160</th>\n",
       "      <th>x_161</th>\n",
       "      <th>x_162</th>\n",
       "      <th>x_163</th>\n",
       "      <th>x_164</th>\n",
       "      <th>x_165</th>\n",
       "      <th>x_166</th>\n",
       "      <th>x_167</th>\n",
       "      <th>x_168</th>\n",
       "      <th>x_169</th>\n",
       "      <th>x_170</th>\n",
       "      <th>x_171</th>\n",
       "      <th>x_172</th>\n",
       "      <th>x_173</th>\n",
       "      <th>x_174</th>\n",
       "      <th>x_175</th>\n",
       "      <th>x_176</th>\n",
       "      <th>x_177</th>\n",
       "      <th>x_178</th>\n",
       "      <th>x_179</th>\n",
       "      <th>x_180</th>\n",
       "      <th>x_181</th>\n",
       "      <th>x_182</th>\n",
       "      <th>x_183</th>\n",
       "      <th>x_184</th>\n",
       "      <th>x_185</th>\n",
       "      <th>x_186</th>\n",
       "      <th>x_187</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041199</td>\n",
       "      <td>0.112360</td>\n",
       "      <td>0.146067</td>\n",
       "      <td>0.202247</td>\n",
       "      <td>0.322097</td>\n",
       "      <td>0.363296</td>\n",
       "      <td>0.413858</td>\n",
       "      <td>0.426966</td>\n",
       "      <td>0.485019</td>\n",
       "      <td>0.511236</td>\n",
       "      <td>0.520599</td>\n",
       "      <td>0.548689</td>\n",
       "      <td>0.599251</td>\n",
       "      <td>0.606742</td>\n",
       "      <td>0.640449</td>\n",
       "      <td>0.664794</td>\n",
       "      <td>0.730337</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.852060</td>\n",
       "      <td>0.897004</td>\n",
       "      <td>0.953184</td>\n",
       "      <td>0.970037</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992509</td>\n",
       "      <td>0.985019</td>\n",
       "      <td>0.943820</td>\n",
       "      <td>0.898876</td>\n",
       "      <td>0.823970</td>\n",
       "      <td>0.752809</td>\n",
       "      <td>0.711610</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.602996</td>\n",
       "      <td>0.576779</td>\n",
       "      <td>0.597378</td>\n",
       "      <td>0.670412</td>\n",
       "      <td>0.595506</td>\n",
       "      <td>0.513109</td>\n",
       "      <td>0.423221</td>\n",
       "      <td>0.277154</td>\n",
       "      <td>0.119850</td>\n",
       "      <td>0.082397</td>\n",
       "      <td>0.022472</td>\n",
       "      <td>0.039326</td>\n",
       "      <td>0.054307</td>\n",
       "      <td>0.063670</td>\n",
       "      <td>0.198502</td>\n",
       "      <td>0.303371</td>\n",
       "      <td>0.355805</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.901786</td>\n",
       "      <td>0.760714</td>\n",
       "      <td>0.610714</td>\n",
       "      <td>0.466071</td>\n",
       "      <td>0.385714</td>\n",
       "      <td>0.364286</td>\n",
       "      <td>0.346429</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.305357</td>\n",
       "      <td>0.308929</td>\n",
       "      <td>0.305357</td>\n",
       "      <td>0.291071</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.283929</td>\n",
       "      <td>0.271429</td>\n",
       "      <td>0.255357</td>\n",
       "      <td>0.264286</td>\n",
       "      <td>0.260714</td>\n",
       "      <td>0.251786</td>\n",
       "      <td>0.241071</td>\n",
       "      <td>0.226786</td>\n",
       "      <td>0.217857</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.173214</td>\n",
       "      <td>0.164286</td>\n",
       "      <td>0.160714</td>\n",
       "      <td>0.155357</td>\n",
       "      <td>0.141071</td>\n",
       "      <td>0.144643</td>\n",
       "      <td>0.155357</td>\n",
       "      <td>0.167857</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.192857</td>\n",
       "      <td>0.223214</td>\n",
       "      <td>0.251786</td>\n",
       "      <td>0.255357</td>\n",
       "      <td>0.276786</td>\n",
       "      <td>0.310714</td>\n",
       "      <td>0.323214</td>\n",
       "      <td>0.323214</td>\n",
       "      <td>0.326786</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.346429</td>\n",
       "      <td>0.339286</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.348214</td>\n",
       "      <td>0.346429</td>\n",
       "      <td>0.335714</td>\n",
       "      <td>0.335714</td>\n",
       "      <td>0.339286</td>\n",
       "      <td>0.341071</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.358929</td>\n",
       "      <td>0.328571</td>\n",
       "      <td>0.308929</td>\n",
       "      <td>0.360714</td>\n",
       "      <td>0.455357</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.366071</td>\n",
       "      <td>0.205357</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.048214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041071</td>\n",
       "      <td>0.101786</td>\n",
       "      <td>0.146429</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.246429</td>\n",
       "      <td>0.301786</td>\n",
       "      <td>0.351786</td>\n",
       "      <td>0.382143</td>\n",
       "      <td>0.387500</td>\n",
       "      <td>0.398214</td>\n",
       "      <td>0.407143</td>\n",
       "      <td>0.407143</td>\n",
       "      <td>0.410714</td>\n",
       "      <td>0.421429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.994200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.951276</td>\n",
       "      <td>0.903712</td>\n",
       "      <td>0.917633</td>\n",
       "      <td>0.900232</td>\n",
       "      <td>0.803944</td>\n",
       "      <td>0.656613</td>\n",
       "      <td>0.421114</td>\n",
       "      <td>0.288863</td>\n",
       "      <td>0.290023</td>\n",
       "      <td>0.269142</td>\n",
       "      <td>0.244780</td>\n",
       "      <td>0.230858</td>\n",
       "      <td>0.216937</td>\n",
       "      <td>0.209977</td>\n",
       "      <td>0.206497</td>\n",
       "      <td>0.193735</td>\n",
       "      <td>0.187935</td>\n",
       "      <td>0.179814</td>\n",
       "      <td>0.177494</td>\n",
       "      <td>0.160093</td>\n",
       "      <td>0.142691</td>\n",
       "      <td>0.133411</td>\n",
       "      <td>0.132251</td>\n",
       "      <td>0.121810</td>\n",
       "      <td>0.107889</td>\n",
       "      <td>0.106729</td>\n",
       "      <td>0.113689</td>\n",
       "      <td>0.096288</td>\n",
       "      <td>0.075406</td>\n",
       "      <td>0.066125</td>\n",
       "      <td>0.048724</td>\n",
       "      <td>0.022042</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002320</td>\n",
       "      <td>0.024362</td>\n",
       "      <td>0.046404</td>\n",
       "      <td>0.067285</td>\n",
       "      <td>0.112529</td>\n",
       "      <td>0.155452</td>\n",
       "      <td>0.196056</td>\n",
       "      <td>0.220418</td>\n",
       "      <td>0.241299</td>\n",
       "      <td>0.256380</td>\n",
       "      <td>0.257541</td>\n",
       "      <td>0.252900</td>\n",
       "      <td>0.257541</td>\n",
       "      <td>0.262181</td>\n",
       "      <td>0.257541</td>\n",
       "      <td>0.259861</td>\n",
       "      <td>0.261021</td>\n",
       "      <td>0.269142</td>\n",
       "      <td>0.265661</td>\n",
       "      <td>0.263341</td>\n",
       "      <td>0.263341</td>\n",
       "      <td>0.271462</td>\n",
       "      <td>0.270302</td>\n",
       "      <td>0.270302</td>\n",
       "      <td>0.273782</td>\n",
       "      <td>0.278422</td>\n",
       "      <td>0.278422</td>\n",
       "      <td>0.271462</td>\n",
       "      <td>0.273782</td>\n",
       "      <td>0.278422</td>\n",
       "      <td>0.279582</td>\n",
       "      <td>0.273782</td>\n",
       "      <td>0.277262</td>\n",
       "      <td>0.279582</td>\n",
       "      <td>0.279582</td>\n",
       "      <td>0.278422</td>\n",
       "      <td>0.278422</td>\n",
       "      <td>0.285383</td>\n",
       "      <td>0.283063</td>\n",
       "      <td>0.280742</td>\n",
       "      <td>0.283063</td>\n",
       "      <td>0.287703</td>\n",
       "      <td>0.286543</td>\n",
       "      <td>0.283063</td>\n",
       "      <td>0.287703</td>\n",
       "      <td>0.291183</td>\n",
       "      <td>0.293503</td>\n",
       "      <td>0.290023</td>\n",
       "      <td>0.291183</td>\n",
       "      <td>0.296984</td>\n",
       "      <td>0.294664</td>\n",
       "      <td>0.290023</td>\n",
       "      <td>0.290023</td>\n",
       "      <td>0.295824</td>\n",
       "      <td>0.291183</td>\n",
       "      <td>0.293503</td>\n",
       "      <td>0.293503</td>\n",
       "      <td>0.300464</td>\n",
       "      <td>0.301624</td>\n",
       "      <td>0.296984</td>\n",
       "      <td>0.294664</td>\n",
       "      <td>0.300464</td>\n",
       "      <td>0.294664</td>\n",
       "      <td>0.293503</td>\n",
       "      <td>0.299304</td>\n",
       "      <td>0.303944</td>\n",
       "      <td>0.300464</td>\n",
       "      <td>0.294664</td>\n",
       "      <td>0.299304</td>\n",
       "      <td>0.307425</td>\n",
       "      <td>0.301624</td>\n",
       "      <td>0.300464</td>\n",
       "      <td>0.293503</td>\n",
       "      <td>0.303944</td>\n",
       "      <td>0.303944</td>\n",
       "      <td>0.298144</td>\n",
       "      <td>0.296984</td>\n",
       "      <td>0.303944</td>\n",
       "      <td>0.306264</td>\n",
       "      <td>0.300464</td>\n",
       "      <td>0.301624</td>\n",
       "      <td>0.309745</td>\n",
       "      <td>0.312065</td>\n",
       "      <td>0.307425</td>\n",
       "      <td>0.302784</td>\n",
       "      <td>0.310905</td>\n",
       "      <td>0.308585</td>\n",
       "      <td>0.299304</td>\n",
       "      <td>0.301624</td>\n",
       "      <td>0.307425</td>\n",
       "      <td>0.310905</td>\n",
       "      <td>0.305104</td>\n",
       "      <td>0.308585</td>\n",
       "      <td>0.313225</td>\n",
       "      <td>0.310905</td>\n",
       "      <td>0.309745</td>\n",
       "      <td>0.309745</td>\n",
       "      <td>0.317865</td>\n",
       "      <td>0.315545</td>\n",
       "      <td>0.310905</td>\n",
       "      <td>0.312065</td>\n",
       "      <td>0.317865</td>\n",
       "      <td>0.319026</td>\n",
       "      <td>0.328306</td>\n",
       "      <td>0.341067</td>\n",
       "      <td>0.352668</td>\n",
       "      <td>0.37007</td>\n",
       "      <td>0.390951</td>\n",
       "      <td>0.385151</td>\n",
       "      <td>0.387471</td>\n",
       "      <td>0.37587</td>\n",
       "      <td>0.338747</td>\n",
       "      <td>0.312065</td>\n",
       "      <td>0.308585</td>\n",
       "      <td>0.312065</td>\n",
       "      <td>0.307425</td>\n",
       "      <td>0.301624</td>\n",
       "      <td>0.308585</td>\n",
       "      <td>0.307425</td>\n",
       "      <td>0.300464</td>\n",
       "      <td>0.283063</td>\n",
       "      <td>0.301624</td>\n",
       "      <td>0.402552</td>\n",
       "      <td>0.62181</td>\n",
       "      <td>0.790023</td>\n",
       "      <td>0.75174</td>\n",
       "      <td>0.468677</td>\n",
       "      <td>0.267981</td>\n",
       "      <td>0.349188</td>\n",
       "      <td>0.356148</td>\n",
       "      <td>0.313225</td>\n",
       "      <td>0.295824</td>\n",
       "      <td>0.305104</td>\n",
       "      <td>0.301624</td>\n",
       "      <td>0.302784</td>\n",
       "      <td>0.294664</td>\n",
       "      <td>0.295824</td>\n",
       "      <td>0.300464</td>\n",
       "      <td>0.296984</td>\n",
       "      <td>0.293503</td>\n",
       "      <td>0.290023</td>\n",
       "      <td>0.296984</td>\n",
       "      <td>0.300464</td>\n",
       "      <td>0.294664</td>\n",
       "      <td>0.295824</td>\n",
       "      <td>0.301624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.984472</td>\n",
       "      <td>0.962733</td>\n",
       "      <td>0.663043</td>\n",
       "      <td>0.211180</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.100932</td>\n",
       "      <td>0.177019</td>\n",
       "      <td>0.270186</td>\n",
       "      <td>0.313665</td>\n",
       "      <td>0.307453</td>\n",
       "      <td>0.312112</td>\n",
       "      <td>0.312112</td>\n",
       "      <td>0.313665</td>\n",
       "      <td>0.315217</td>\n",
       "      <td>0.319876</td>\n",
       "      <td>0.316770</td>\n",
       "      <td>0.312112</td>\n",
       "      <td>0.313665</td>\n",
       "      <td>0.319876</td>\n",
       "      <td>0.316770</td>\n",
       "      <td>0.307453</td>\n",
       "      <td>0.313665</td>\n",
       "      <td>0.315217</td>\n",
       "      <td>0.315217</td>\n",
       "      <td>0.322981</td>\n",
       "      <td>0.330745</td>\n",
       "      <td>0.343168</td>\n",
       "      <td>0.355590</td>\n",
       "      <td>0.366460</td>\n",
       "      <td>0.380435</td>\n",
       "      <td>0.394410</td>\n",
       "      <td>0.406832</td>\n",
       "      <td>0.406832</td>\n",
       "      <td>0.411491</td>\n",
       "      <td>0.405280</td>\n",
       "      <td>0.395963</td>\n",
       "      <td>0.377329</td>\n",
       "      <td>0.377329</td>\n",
       "      <td>0.378882</td>\n",
       "      <td>0.369565</td>\n",
       "      <td>0.363354</td>\n",
       "      <td>0.366460</td>\n",
       "      <td>0.366460</td>\n",
       "      <td>0.361801</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.366460</td>\n",
       "      <td>0.369565</td>\n",
       "      <td>0.363354</td>\n",
       "      <td>0.361801</td>\n",
       "      <td>0.366460</td>\n",
       "      <td>0.372671</td>\n",
       "      <td>0.371118</td>\n",
       "      <td>0.369565</td>\n",
       "      <td>0.369565</td>\n",
       "      <td>0.378882</td>\n",
       "      <td>0.366460</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.371118</td>\n",
       "      <td>0.375776</td>\n",
       "      <td>0.372671</td>\n",
       "      <td>0.364907</td>\n",
       "      <td>0.369565</td>\n",
       "      <td>0.374224</td>\n",
       "      <td>0.371118</td>\n",
       "      <td>0.372671</td>\n",
       "      <td>0.380435</td>\n",
       "      <td>0.389752</td>\n",
       "      <td>0.394410</td>\n",
       "      <td>0.408385</td>\n",
       "      <td>0.416149</td>\n",
       "      <td>0.439441</td>\n",
       "      <td>0.456522</td>\n",
       "      <td>0.470497</td>\n",
       "      <td>0.451863</td>\n",
       "      <td>0.459627</td>\n",
       "      <td>0.453416</td>\n",
       "      <td>0.427019</td>\n",
       "      <td>0.399068</td>\n",
       "      <td>0.394410</td>\n",
       "      <td>0.369565</td>\n",
       "      <td>0.354037</td>\n",
       "      <td>0.363354</td>\n",
       "      <td>0.364907</td>\n",
       "      <td>0.366460</td>\n",
       "      <td>0.364907</td>\n",
       "      <td>0.388199</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.734472</td>\n",
       "      <td>0.911491</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.919255</td>\n",
       "      <td>0.614907</td>\n",
       "      <td>0.406832</td>\n",
       "      <td>0.372671</td>\n",
       "      <td>0.349379</td>\n",
       "      <td>0.315217</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.313665</td>\n",
       "      <td>0.312112</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.298137</td>\n",
       "      <td>0.301242</td>\n",
       "      <td>0.307453</td>\n",
       "      <td>0.298137</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.619217</td>\n",
       "      <td>0.489324</td>\n",
       "      <td>0.327402</td>\n",
       "      <td>0.110320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060498</td>\n",
       "      <td>0.108541</td>\n",
       "      <td>0.108541</td>\n",
       "      <td>0.145907</td>\n",
       "      <td>0.192171</td>\n",
       "      <td>0.222420</td>\n",
       "      <td>0.259786</td>\n",
       "      <td>0.279359</td>\n",
       "      <td>0.282918</td>\n",
       "      <td>0.279359</td>\n",
       "      <td>0.275801</td>\n",
       "      <td>0.281139</td>\n",
       "      <td>0.288256</td>\n",
       "      <td>0.286477</td>\n",
       "      <td>0.281139</td>\n",
       "      <td>0.279359</td>\n",
       "      <td>0.290036</td>\n",
       "      <td>0.291815</td>\n",
       "      <td>0.297153</td>\n",
       "      <td>0.313167</td>\n",
       "      <td>0.334520</td>\n",
       "      <td>0.357651</td>\n",
       "      <td>0.380783</td>\n",
       "      <td>0.405694</td>\n",
       "      <td>0.435943</td>\n",
       "      <td>0.464413</td>\n",
       "      <td>0.476868</td>\n",
       "      <td>0.491103</td>\n",
       "      <td>0.508897</td>\n",
       "      <td>0.501779</td>\n",
       "      <td>0.496441</td>\n",
       "      <td>0.483986</td>\n",
       "      <td>0.471530</td>\n",
       "      <td>0.457295</td>\n",
       "      <td>0.430605</td>\n",
       "      <td>0.416370</td>\n",
       "      <td>0.407473</td>\n",
       "      <td>0.386121</td>\n",
       "      <td>0.359431</td>\n",
       "      <td>0.350534</td>\n",
       "      <td>0.354093</td>\n",
       "      <td>0.341637</td>\n",
       "      <td>0.330961</td>\n",
       "      <td>0.327402</td>\n",
       "      <td>0.330961</td>\n",
       "      <td>0.327402</td>\n",
       "      <td>0.313167</td>\n",
       "      <td>0.314947</td>\n",
       "      <td>0.322064</td>\n",
       "      <td>0.318505</td>\n",
       "      <td>0.313167</td>\n",
       "      <td>0.311388</td>\n",
       "      <td>0.316726</td>\n",
       "      <td>0.311388</td>\n",
       "      <td>0.302491</td>\n",
       "      <td>0.298932</td>\n",
       "      <td>0.307829</td>\n",
       "      <td>0.304270</td>\n",
       "      <td>0.295374</td>\n",
       "      <td>0.290036</td>\n",
       "      <td>0.298932</td>\n",
       "      <td>0.291815</td>\n",
       "      <td>0.290036</td>\n",
       "      <td>0.290036</td>\n",
       "      <td>0.295374</td>\n",
       "      <td>0.288256</td>\n",
       "      <td>0.290036</td>\n",
       "      <td>0.288256</td>\n",
       "      <td>0.288256</td>\n",
       "      <td>0.288256</td>\n",
       "      <td>0.286477</td>\n",
       "      <td>0.291815</td>\n",
       "      <td>0.297153</td>\n",
       "      <td>0.302491</td>\n",
       "      <td>0.300712</td>\n",
       "      <td>0.309609</td>\n",
       "      <td>0.323843</td>\n",
       "      <td>0.330961</td>\n",
       "      <td>0.327402</td>\n",
       "      <td>0.320285</td>\n",
       "      <td>0.314947</td>\n",
       "      <td>0.295374</td>\n",
       "      <td>0.281139</td>\n",
       "      <td>0.274021</td>\n",
       "      <td>0.266904</td>\n",
       "      <td>0.263345</td>\n",
       "      <td>0.261566</td>\n",
       "      <td>0.263345</td>\n",
       "      <td>0.272242</td>\n",
       "      <td>0.277580</td>\n",
       "      <td>0.295374</td>\n",
       "      <td>0.354093</td>\n",
       "      <td>0.471530</td>\n",
       "      <td>0.658363</td>\n",
       "      <td>0.850534</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976868</td>\n",
       "      <td>0.542705</td>\n",
       "      <td>0.193950</td>\n",
       "      <td>0.185053</td>\n",
       "      <td>0.218861</td>\n",
       "      <td>0.224199</td>\n",
       "      <td>0.201068</td>\n",
       "      <td>0.204626</td>\n",
       "      <td>0.209964</td>\n",
       "      <td>0.201068</td>\n",
       "      <td>0.197509</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        x_1       x_2       x_3       x_4       x_5       x_6       x_7  \\\n",
       "0  0.000000  0.041199  0.112360  0.146067  0.202247  0.322097  0.363296   \n",
       "1  1.000000  0.901786  0.760714  0.610714  0.466071  0.385714  0.364286   \n",
       "2  0.994200  1.000000  0.951276  0.903712  0.917633  0.900232  0.803944   \n",
       "3  0.984472  0.962733  0.663043  0.211180  0.000000  0.032609  0.100932   \n",
       "4  0.619217  0.489324  0.327402  0.110320  0.000000  0.060498  0.108541   \n",
       "\n",
       "        x_8       x_9      x_10      x_11      x_12      x_13      x_14  \\\n",
       "0  0.413858  0.426966  0.485019  0.511236  0.520599  0.548689  0.599251   \n",
       "1  0.346429  0.314286  0.305357  0.308929  0.305357  0.291071  0.285714   \n",
       "2  0.656613  0.421114  0.288863  0.290023  0.269142  0.244780  0.230858   \n",
       "3  0.177019  0.270186  0.313665  0.307453  0.312112  0.312112  0.313665   \n",
       "4  0.108541  0.145907  0.192171  0.222420  0.259786  0.279359  0.282918   \n",
       "\n",
       "       x_15      x_16      x_17      x_18      x_19      x_20      x_21  \\\n",
       "0  0.606742  0.640449  0.664794  0.730337  0.780899  0.852060  0.897004   \n",
       "1  0.283929  0.271429  0.255357  0.264286  0.260714  0.251786  0.241071   \n",
       "2  0.216937  0.209977  0.206497  0.193735  0.187935  0.179814  0.177494   \n",
       "3  0.315217  0.319876  0.316770  0.312112  0.313665  0.319876  0.316770   \n",
       "4  0.279359  0.275801  0.281139  0.288256  0.286477  0.281139  0.279359   \n",
       "\n",
       "       x_22      x_23      x_24      x_25      x_26      x_27      x_28  \\\n",
       "0  0.953184  0.970037  1.000000  0.992509  0.985019  0.943820  0.898876   \n",
       "1  0.226786  0.217857  0.200000  0.173214  0.164286  0.160714  0.155357   \n",
       "2  0.160093  0.142691  0.133411  0.132251  0.121810  0.107889  0.106729   \n",
       "3  0.307453  0.313665  0.315217  0.315217  0.322981  0.330745  0.343168   \n",
       "4  0.290036  0.291815  0.297153  0.313167  0.334520  0.357651  0.380783   \n",
       "\n",
       "       x_29      x_30      x_31      x_32      x_33      x_34      x_35  \\\n",
       "0  0.823970  0.752809  0.711610  0.666667  0.602996  0.576779  0.597378   \n",
       "1  0.141071  0.144643  0.155357  0.167857  0.175000  0.192857  0.223214   \n",
       "2  0.113689  0.096288  0.075406  0.066125  0.048724  0.022042  0.000000   \n",
       "3  0.355590  0.366460  0.380435  0.394410  0.406832  0.406832  0.411491   \n",
       "4  0.405694  0.435943  0.464413  0.476868  0.491103  0.508897  0.501779   \n",
       "\n",
       "       x_36      x_37      x_38      x_39      x_40      x_41      x_42  \\\n",
       "0  0.670412  0.595506  0.513109  0.423221  0.277154  0.119850  0.082397   \n",
       "1  0.251786  0.255357  0.276786  0.310714  0.323214  0.323214  0.326786   \n",
       "2  0.002320  0.024362  0.046404  0.067285  0.112529  0.155452  0.196056   \n",
       "3  0.405280  0.395963  0.377329  0.377329  0.378882  0.369565  0.363354   \n",
       "4  0.496441  0.483986  0.471530  0.457295  0.430605  0.416370  0.407473   \n",
       "\n",
       "       x_43      x_44      x_45      x_46      x_47      x_48      x_49  \\\n",
       "0  0.022472  0.039326  0.054307  0.063670  0.198502  0.303371  0.355805   \n",
       "1  0.342857  0.346429  0.339286  0.342857  0.348214  0.346429  0.335714   \n",
       "2  0.220418  0.241299  0.256380  0.257541  0.252900  0.257541  0.262181   \n",
       "3  0.366460  0.366460  0.361801  0.357143  0.366460  0.369565  0.363354   \n",
       "4  0.386121  0.359431  0.350534  0.354093  0.341637  0.330961  0.327402   \n",
       "\n",
       "       x_50      x_51      x_52      x_53      x_54      x_55      x_56  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.335714  0.339286  0.341071  0.342857  0.357143  0.358929  0.328571   \n",
       "2  0.257541  0.259861  0.261021  0.269142  0.265661  0.263341  0.263341   \n",
       "3  0.361801  0.366460  0.372671  0.371118  0.369565  0.369565  0.378882   \n",
       "4  0.330961  0.327402  0.313167  0.314947  0.322064  0.318505  0.313167   \n",
       "\n",
       "       x_57      x_58      x_59      x_60      x_61      x_62      x_63  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.308929  0.360714  0.455357  0.457143  0.366071  0.205357  0.114286   \n",
       "2  0.271462  0.270302  0.270302  0.273782  0.278422  0.278422  0.271462   \n",
       "3  0.366460  0.357143  0.371118  0.375776  0.372671  0.364907  0.369565   \n",
       "4  0.311388  0.316726  0.311388  0.302491  0.298932  0.307829  0.304270   \n",
       "\n",
       "       x_64      x_65      x_66      x_67      x_68      x_69      x_70  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.048214  0.000000  0.041071  0.101786  0.146429  0.187500  0.246429   \n",
       "2  0.273782  0.278422  0.279582  0.273782  0.277262  0.279582  0.279582   \n",
       "3  0.374224  0.371118  0.372671  0.380435  0.389752  0.394410  0.408385   \n",
       "4  0.295374  0.290036  0.298932  0.291815  0.290036  0.290036  0.295374   \n",
       "\n",
       "       x_71      x_72      x_73      x_74      x_75      x_76      x_77  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.301786  0.351786  0.382143  0.387500  0.398214  0.407143  0.407143   \n",
       "2  0.278422  0.278422  0.285383  0.283063  0.280742  0.283063  0.287703   \n",
       "3  0.416149  0.439441  0.456522  0.470497  0.451863  0.459627  0.453416   \n",
       "4  0.288256  0.290036  0.288256  0.288256  0.288256  0.286477  0.291815   \n",
       "\n",
       "       x_78      x_79      x_80      x_81      x_82      x_83      x_84  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.410714  0.421429  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.286543  0.283063  0.287703  0.291183  0.293503  0.290023  0.291183   \n",
       "3  0.427019  0.399068  0.394410  0.369565  0.354037  0.363354  0.364907   \n",
       "4  0.297153  0.302491  0.300712  0.309609  0.323843  0.330961  0.327402   \n",
       "\n",
       "       x_85      x_86      x_87      x_88      x_89      x_90      x_91  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.296984  0.294664  0.290023  0.290023  0.295824  0.291183  0.293503   \n",
       "3  0.366460  0.364907  0.388199  0.535714  0.734472  0.911491  1.000000   \n",
       "4  0.320285  0.314947  0.295374  0.281139  0.274021  0.266904  0.263345   \n",
       "\n",
       "       x_92      x_93      x_94      x_95      x_96      x_97      x_98  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.293503  0.300464  0.301624  0.296984  0.294664  0.300464  0.294664   \n",
       "3  0.919255  0.614907  0.406832  0.372671  0.349379  0.315217  0.304348   \n",
       "4  0.261566  0.263345  0.272242  0.277580  0.295374  0.354093  0.471530   \n",
       "\n",
       "       x_99     x_100     x_101     x_102     x_103     x_104     x_105  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.293503  0.299304  0.303944  0.300464  0.294664  0.299304  0.307425   \n",
       "3  0.313665  0.312112  0.304348  0.298137  0.301242  0.307453  0.298137   \n",
       "4  0.658363  0.850534  1.000000  0.976868  0.542705  0.193950  0.185053   \n",
       "\n",
       "      x_106     x_107     x_108     x_109     x_110     x_111     x_112  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.301624  0.300464  0.293503  0.303944  0.303944  0.298144  0.296984   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.218861  0.224199  0.201068  0.204626  0.209964  0.201068  0.197509   \n",
       "\n",
       "      x_113     x_114     x_115     x_116     x_117     x_118     x_119  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.303944  0.306264  0.300464  0.301624  0.309745  0.312065  0.307425   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "      x_120     x_121     x_122     x_123     x_124     x_125     x_126  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.302784  0.310905  0.308585  0.299304  0.301624  0.307425  0.310905   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "      x_127     x_128     x_129     x_130     x_131     x_132     x_133  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.305104  0.308585  0.313225  0.310905  0.309745  0.309745  0.317865   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "      x_134     x_135     x_136     x_137     x_138     x_139     x_140  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.315545  0.310905  0.312065  0.317865  0.319026  0.328306  0.341067   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "      x_141    x_142     x_143     x_144     x_145    x_146     x_147  \\\n",
       "0  0.000000  0.00000  0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "1  0.000000  0.00000  0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "2  0.352668  0.37007  0.390951  0.385151  0.387471  0.37587  0.338747   \n",
       "3  0.000000  0.00000  0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "4  0.000000  0.00000  0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "\n",
       "      x_148     x_149     x_150     x_151     x_152     x_153     x_154  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.312065  0.308585  0.312065  0.307425  0.301624  0.308585  0.307425   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "      x_155     x_156     x_157     x_158    x_159     x_160    x_161  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000  0.00000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000  0.00000   \n",
       "2  0.300464  0.283063  0.301624  0.402552  0.62181  0.790023  0.75174   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000  0.00000   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000  0.00000   \n",
       "\n",
       "      x_162     x_163     x_164     x_165     x_166     x_167     x_168  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.468677  0.267981  0.349188  0.356148  0.313225  0.295824  0.305104   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "      x_169     x_170     x_171     x_172     x_173     x_174     x_175  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.301624  0.302784  0.294664  0.295824  0.300464  0.296984  0.293503   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "      x_176     x_177     x_178     x_179     x_180     x_181  x_182  x_183  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000    0.0    0.0   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000    0.0    0.0   \n",
       "2  0.290023  0.296984  0.300464  0.294664  0.295824  0.301624    0.0    0.0   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000    0.0    0.0   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000    0.0    0.0   \n",
       "\n",
       "   x_184  x_185  x_186  x_187  target  \n",
       "0    0.0    0.0    0.0    0.0       1  \n",
       "1    0.0    0.0    0.0    0.0       1  \n",
       "2    0.0    0.0    0.0    0.0       1  \n",
       "3    0.0    0.0    0.0    0.0       1  \n",
       "4    0.0    0.0    0.0    0.0       1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "data = pd.read_csv('data/electrocardiograms.csv')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19565, 188)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "💓 Each observation of the dataset is a sequence of measured heartbeats, taken from a patient's electrocardiogram (ECG).\n",
    "\n",
    "🎯 The target is binary and defines whether the heartbeat shows:\n",
    "* a risk of cardiovascular disease 🔴 (1)\n",
    "* or not 🟢 (0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓\n",
    "\n",
    "Plot an observation of each target class to get a visual idea of what the numbers represent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='target', ylabel='count'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='target', data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Questions** ❓\n",
    "\n",
    "* How many observations of at-risk heartbeats are there? Save your answer as `at_risk_count`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1448"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "at_risk_count= data[['target']].value_counts()[1]\n",
    "at_risk_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* How many observations of healthy heartbeats are there? Save your answer as `healthy_count`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18117"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "healthy_count= data[['target']].value_counts()[0]\n",
    "healthy_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👩🏻‍🏫 In certain cases, the class balance is representative of the true class distribution. This is the case here: the vast majority of people actually have healthy hearts. In such case, we preserve the class distribution to train the model based on reality, and adapt our modeling approach accordingly.\n",
    "\n",
    "[Centers for Disease Control and Prevention - Heart Disease Facts](https://www.cdc.gov/heartdisease/facts.htm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🧪 **Check your code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.10.6, pytest-7.1.3, pluggy-1.0.0 -- /home/parissa/.pyenv/versions/lewagon/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/parissa/code/ParissaPeimaniyfard/05-ML/03-Performance-metrics/data-electrocardiograms/tests\n",
      "plugins: typeguard-2.13.3, anyio-3.6.2, asyncio-0.19.0\n",
      "asyncio: mode=strict\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 2 items\n",
      "\n",
      "test_class_balance.py::TestClass_balance::test_at_risk_count \u001b[32mPASSED\u001b[0m\u001b[32m      [ 50%]\u001b[0m\n",
      "test_class_balance.py::TestClass_balance::test_healthy_count \u001b[32mPASSED\u001b[0m\u001b[32m      [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 0.11s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "💯 You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/class_balance.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed class_balance step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('class_balance',\n",
    "                         healthy = healthy_count,\n",
    "                         at_risk = at_risk_count)\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##  (3) Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "🎯 Your task is to **flag heartbeats that are at risk of cardiovascular diseases.**\n",
    "\n",
    "👇 Let's start by investigating the performance of a `LogisticRegression` on that task. Use a ***cross-validation to evaluate the model*** on the following metrics:\n",
    "- Accuracy\n",
    "- Recall\n",
    "- Precision\n",
    "- F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true,
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "❓ **Question (Ratio of correct predictions)** ❓ \n",
    "\n",
    "What is the ratio of correct predictions for this model ? Save your answer under variable name `correct_pred_ratio`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true,
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "❓ **Question (Ability to flag at-risk patients)** ❓ \n",
    "\n",
    "What percentage of at-risk heartbeats is the model able to flag? Save your answer under variable name `flag_ratio`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true,
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "❓ **Question (Ability to flag correctly)** ❓ \n",
    "\n",
    "When the model signals an at-risk heartbeat, how often is it correct? Save your answer under variable name `correct_detection_ratio`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true,
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "❓ **Question (Detecting as many at-risk patients as possible without too many false alarms)** ❓ \n",
    "\n",
    "What is the model's ability to flag as many at-risk heartbeats as possible while limiting false alarms?  Save your answer under variable name `aggregated_metric`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true,
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "🧪 **Check your code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'correct_pred_ratio' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnbresult\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChallengeResult\n\u001b[1;32m      3\u001b[0m result \u001b[38;5;241m=\u001b[39m ChallengeResult(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogistic_regression_evaluation\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m----> 4\u001b[0m                          accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mcorrect_pred_ratio\u001b[49m,\n\u001b[1;32m      5\u001b[0m                          recall \u001b[38;5;241m=\u001b[39m flag_ratio,\n\u001b[1;32m      6\u001b[0m                          precision \u001b[38;5;241m=\u001b[39m correct_detection_ratio,\n\u001b[1;32m      7\u001b[0m                          f1 \u001b[38;5;241m=\u001b[39m aggregated_metric)\n\u001b[1;32m      8\u001b[0m result\u001b[38;5;241m.\u001b[39mwrite()\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(result\u001b[38;5;241m.\u001b[39mcheck())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'correct_pred_ratio' is not defined"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('logistic_regression_evaluation',\n",
    "                         accuracy = correct_pred_ratio,\n",
    "                         recall = flag_ratio,\n",
    "                         precision = correct_detection_ratio,\n",
    "                         f1 = aggregated_metric)\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "▶️ Run the following cell before moving on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f\"You should have noticed that the model was able to predict correctly in {int(round(correct_pred_ratio,2)*100)} cases out of 100. \")\n",
    "\n",
    "print(f\"However, it was able to capture only {round(flag_ratio,2)*100} % of the at-risk patients\")\n",
    "\n",
    "print(\"Why ? Let's print a confusion matrix!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👇 Using `ConfusionMatrixDisplay` ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html#sklearn.metrics.ConfusionMatrixDisplay)),  visualize the predictions breakdown of the Logistic Regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>💡 Hints</summary>\n",
    "\n",
    "    \n",
    "1. [from_estimator](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html#sklearn.metrics.ConfusionMatrixDisplay.from_estimator)    \n",
    "2. [from_predictions](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html#sklearn.metrics.ConfusionMatrixDisplay.from_predictions)\n",
    "    \n",
    "- Don't forget to to go back to the **Holdout method** to [`train-test-split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) your dataset and look at the confusion matrix on the test set.  \n",
    "</details>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f0fe216cd00>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X=data.drop(columns=['target'])\n",
    "y= data['target']\n",
    "model_log = LogisticRegression(max_iter=1000)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "model_log.fit(X_train,y_train)\n",
    "ConfusionMatrixDisplay.from_estimator(model_log, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_predic_log= model_log.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_log= 0.94\n",
      "precision_score_log= 0.67\n",
      "recall_score_log= 0.33\n",
      "f1_score_log= 0.44\n"
     ]
    }
   ],
   "source": [
    "print('accuracy_log=', round(accuracy_score(y_test,y_predic_log),2))\n",
    "print('precision_score_log=', round(precision_score(y_test,y_predic_log),2))\n",
    "print('recall_score_log=', round(recall_score(y_test,y_predic_log),2))\n",
    "print('f1_score_log=', round(f1_score(y_test,y_predic_log),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ℹ️ The confusion matrix should show that the model is influenced by the class imbalance: it predicts the heartbeats to be healthy most of the time. Due to this behaviour, the model is often correct and has a **high accuracy**. However, this also causes it to miss out on many at-risk heartbeats: it has **bad recall**...\n",
    "\n",
    "👉 This model is therefore poor at the task of **flagging at-risk observations**.\n",
    "\n",
    "❗️ Don't be fooled by the accuracy and look at the metric that corresponds to your task! ❗️"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5) KNN Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question (Classification Model Selection)** ❓ \n",
    "\n",
    "Would a default KNN classifier perform better at the task of flagging at-risk observations?\n",
    "\n",
    "Save the you answer under `best_model` as \"KNN\" or \"LogisticRegression\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['target'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4547,    3],\n",
       "       [ 100,  242]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_knn= KNeighborsRegressor()\n",
    "model_knn.fit(X_train,y_train)\n",
    "y_pred_knn = model_knn.predict(X_test)\n",
    "y_pred_knn = y_pred_knn.astype(int)\n",
    "confusion_matrix(y_test, y_pred_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f8789dfbc10>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_knn= KNeighborsClassifier()\n",
    "model_knn.fit(X_train,y_train)\n",
    "# y_pred_knn = model_knn.predict(X_test)\n",
    "# y_pred_knn = y_pred_knn.astype(int)\n",
    "ConfusionMatrixDisplay.from_estimator(model_knn, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_knn = model_knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [19565, 4892]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy_knn=\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mround\u001b[39m(\u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_pred_knn\u001b[49m\u001b[43m)\u001b[49m,\u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision_score_knn=\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mround\u001b[39m(precision_score(y_test,y_pred_knn),\u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall_score_knn=\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mround\u001b[39m(recall_score(y_test,y_pred_knn),\u001b[38;5;241m2\u001b[39m))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/sklearn/metrics/_classification.py:220\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[0;32m--> 220\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/sklearn/metrics/_classification.py:84\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m     type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     86\u001b[0m     type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/sklearn/utils/validation.py:407\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    405\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 407\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    408\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    409\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    410\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [19565, 4892]"
     ]
    }
   ],
   "source": [
    "print('accuracy_knn=', round(accuracy_score(y, y_pred_knn),2))\n",
    "print('precision_score_knn=', round(precision_score(y_test,y_pred_knn),2))\n",
    "print('recall_score_knn=', round(recall_score(y_test,y_pred_knn),2))\n",
    "print('f1_score_knn=', round(f1_score(y_test,y_pred_knn),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model= 'KNN'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "💪 For this ECG dataset, the KNN Classifier should have a much higher recall than the LogisticRegression and therefore is better suited for the task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🧪 **Check your code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.10.6, pytest-7.1.3, pluggy-1.0.0 -- /home/parissa/.pyenv/versions/lewagon/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/parissa/code/ParissaPeimaniyfard/05-ML/03-Performance-metrics/data-electrocardiograms/tests\n",
      "plugins: typeguard-2.13.3, anyio-3.6.2, asyncio-0.19.0\n",
      "asyncio: mode=strict\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 1 item\n",
      "\n",
      "test_best_model.py::TestBest_model::test_best_model \u001b[32mPASSED\u001b[0m\u001b[32m               [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.01s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "💯 You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/best_model.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed best_model step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('best_model',\n",
    "                         model = best_model)\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (6) Classification Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have selected the KNN model thanks to its higherbest recall, let's have a look at the other classification performance metrics>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question (Classification Report)** ❓\n",
    "\n",
    "Print out a [`classification_report`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html) of the KNN model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary> 💡 <i>Hint</i>  </summary>\n",
    "    \n",
    "* You will need to pass the predictions of the model to a `classification_report`.\n",
    "    \n",
    "* SkLearn's [`cross_val_predict`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html) might help 😉\n",
    "</details>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predknn_cros= cross_val_predict(model_knn, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true,
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_predknn_cros\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2539\u001b[0m, in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2405\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m   2406\u001b[0m     {\n\u001b[1;32m   2407\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2430\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2431\u001b[0m ):\n\u001b[1;32m   2432\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a text report showing the main classification metrics.\u001b[39;00m\n\u001b[1;32m   2433\u001b[0m \n\u001b[1;32m   2434\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <classification_report>`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2536\u001b[0m \u001b[38;5;124;03m    <BLANKLINE>\u001b[39;00m\n\u001b[1;32m   2537\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2539\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2541\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2542\u001b[0m         labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/sklearn/metrics/_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     90\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     95\u001b[0m             type_true, type_pred\n\u001b[1;32m     96\u001b[0m         )\n\u001b[1;32m     97\u001b[0m     )\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    100\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "print(classification_report(y , y_predknn_cros)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_predknn_cros\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2539\u001b[0m, in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2405\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m   2406\u001b[0m     {\n\u001b[1;32m   2407\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2430\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2431\u001b[0m ):\n\u001b[1;32m   2432\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a text report showing the main classification metrics.\u001b[39;00m\n\u001b[1;32m   2433\u001b[0m \n\u001b[1;32m   2434\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <classification_report>`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2536\u001b[0m \u001b[38;5;124;03m    <BLANKLINE>\u001b[39;00m\n\u001b[1;32m   2537\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2539\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2541\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2542\u001b[0m         labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/sklearn/metrics/_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     90\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     95\u001b[0m             type_true, type_pred\n\u001b[1;32m     96\u001b[0m         )\n\u001b[1;32m     97\u001b[0m     )\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    100\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    " classification_report(y , y_predknn_cros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question (Reading the report)** ❓\n",
    "\n",
    "Among the heartbeats predicted at-risk, what is the ratio of correct predictions ? \n",
    "\n",
    "In mathematical terms, can you read the ratio $ \\frac{TP}{TP + FP} $ in the report? What is the name of this classification metrics ? \n",
    "\n",
    "Save your answer as a float under `correct_at_risk_predictions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "correct_at_risk_predictions= 0.94"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🧪 **Check your code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.10.6, pytest-7.1.3, pluggy-1.0.0 -- /home/parissa/.pyenv/versions/lewagon/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/parissa/code/ParissaPeimaniyfard/05-ML/03-Performance-metrics/data-electrocardiograms/tests\n",
      "plugins: typeguard-2.13.3, anyio-3.6.2, asyncio-0.19.0\n",
      "asyncio: mode=strict\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 1 item\n",
      "\n",
      "test_precision.py::TestPrecision::test_precision \u001b[32mPASSED\u001b[0m\u001b[32m                  [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.01s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "💯 You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/precision.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed precision step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('precision',\n",
    "                         precision = correct_at_risk_predictions)\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (7) Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question (Predicting)** ❓\n",
    "\n",
    "A patient comes to you for a second opinion because  he was told that based on his heartbeats, this patient may be at-risk.  \n",
    "\n",
    "According to your optimal model, is he at-risk or not?  \n",
    "\n",
    "Save the prediction of your model under variable name `prediction` as \"at risk\" or \"healthy\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>x_5</th>\n",
       "      <th>x_6</th>\n",
       "      <th>x_7</th>\n",
       "      <th>x_8</th>\n",
       "      <th>x_9</th>\n",
       "      <th>x_10</th>\n",
       "      <th>x_11</th>\n",
       "      <th>x_12</th>\n",
       "      <th>x_13</th>\n",
       "      <th>x_14</th>\n",
       "      <th>x_15</th>\n",
       "      <th>x_16</th>\n",
       "      <th>x_17</th>\n",
       "      <th>x_18</th>\n",
       "      <th>x_19</th>\n",
       "      <th>x_20</th>\n",
       "      <th>x_21</th>\n",
       "      <th>x_22</th>\n",
       "      <th>x_23</th>\n",
       "      <th>x_24</th>\n",
       "      <th>x_25</th>\n",
       "      <th>x_26</th>\n",
       "      <th>x_27</th>\n",
       "      <th>x_28</th>\n",
       "      <th>x_29</th>\n",
       "      <th>x_30</th>\n",
       "      <th>x_31</th>\n",
       "      <th>x_32</th>\n",
       "      <th>x_33</th>\n",
       "      <th>x_34</th>\n",
       "      <th>x_35</th>\n",
       "      <th>x_36</th>\n",
       "      <th>x_37</th>\n",
       "      <th>x_38</th>\n",
       "      <th>x_39</th>\n",
       "      <th>x_40</th>\n",
       "      <th>x_41</th>\n",
       "      <th>x_42</th>\n",
       "      <th>x_43</th>\n",
       "      <th>x_44</th>\n",
       "      <th>x_45</th>\n",
       "      <th>x_46</th>\n",
       "      <th>x_47</th>\n",
       "      <th>x_48</th>\n",
       "      <th>x_49</th>\n",
       "      <th>x_50</th>\n",
       "      <th>x_51</th>\n",
       "      <th>x_52</th>\n",
       "      <th>x_53</th>\n",
       "      <th>x_54</th>\n",
       "      <th>x_55</th>\n",
       "      <th>x_56</th>\n",
       "      <th>x_57</th>\n",
       "      <th>x_58</th>\n",
       "      <th>x_59</th>\n",
       "      <th>x_60</th>\n",
       "      <th>x_61</th>\n",
       "      <th>x_62</th>\n",
       "      <th>x_63</th>\n",
       "      <th>x_64</th>\n",
       "      <th>x_65</th>\n",
       "      <th>x_66</th>\n",
       "      <th>x_67</th>\n",
       "      <th>x_68</th>\n",
       "      <th>x_69</th>\n",
       "      <th>x_70</th>\n",
       "      <th>x_71</th>\n",
       "      <th>x_72</th>\n",
       "      <th>x_73</th>\n",
       "      <th>x_74</th>\n",
       "      <th>x_75</th>\n",
       "      <th>x_76</th>\n",
       "      <th>x_77</th>\n",
       "      <th>x_78</th>\n",
       "      <th>x_79</th>\n",
       "      <th>x_80</th>\n",
       "      <th>x_81</th>\n",
       "      <th>x_82</th>\n",
       "      <th>x_83</th>\n",
       "      <th>x_84</th>\n",
       "      <th>x_85</th>\n",
       "      <th>x_86</th>\n",
       "      <th>x_87</th>\n",
       "      <th>x_88</th>\n",
       "      <th>x_89</th>\n",
       "      <th>x_90</th>\n",
       "      <th>x_91</th>\n",
       "      <th>x_92</th>\n",
       "      <th>x_93</th>\n",
       "      <th>x_94</th>\n",
       "      <th>x_95</th>\n",
       "      <th>x_96</th>\n",
       "      <th>x_97</th>\n",
       "      <th>x_98</th>\n",
       "      <th>x_99</th>\n",
       "      <th>x_100</th>\n",
       "      <th>x_101</th>\n",
       "      <th>x_102</th>\n",
       "      <th>x_103</th>\n",
       "      <th>x_104</th>\n",
       "      <th>x_105</th>\n",
       "      <th>x_106</th>\n",
       "      <th>x_107</th>\n",
       "      <th>x_108</th>\n",
       "      <th>x_109</th>\n",
       "      <th>x_110</th>\n",
       "      <th>x_111</th>\n",
       "      <th>x_112</th>\n",
       "      <th>x_113</th>\n",
       "      <th>x_114</th>\n",
       "      <th>x_115</th>\n",
       "      <th>x_116</th>\n",
       "      <th>x_117</th>\n",
       "      <th>x_118</th>\n",
       "      <th>x_119</th>\n",
       "      <th>x_120</th>\n",
       "      <th>x_121</th>\n",
       "      <th>x_122</th>\n",
       "      <th>x_123</th>\n",
       "      <th>x_124</th>\n",
       "      <th>x_125</th>\n",
       "      <th>x_126</th>\n",
       "      <th>x_127</th>\n",
       "      <th>x_128</th>\n",
       "      <th>x_129</th>\n",
       "      <th>x_130</th>\n",
       "      <th>x_131</th>\n",
       "      <th>x_132</th>\n",
       "      <th>x_133</th>\n",
       "      <th>x_134</th>\n",
       "      <th>x_135</th>\n",
       "      <th>x_136</th>\n",
       "      <th>x_137</th>\n",
       "      <th>x_138</th>\n",
       "      <th>x_139</th>\n",
       "      <th>x_140</th>\n",
       "      <th>x_141</th>\n",
       "      <th>x_142</th>\n",
       "      <th>x_143</th>\n",
       "      <th>x_144</th>\n",
       "      <th>x_145</th>\n",
       "      <th>x_146</th>\n",
       "      <th>x_147</th>\n",
       "      <th>x_148</th>\n",
       "      <th>x_149</th>\n",
       "      <th>x_150</th>\n",
       "      <th>x_151</th>\n",
       "      <th>x_152</th>\n",
       "      <th>x_153</th>\n",
       "      <th>x_154</th>\n",
       "      <th>x_155</th>\n",
       "      <th>x_156</th>\n",
       "      <th>x_157</th>\n",
       "      <th>x_158</th>\n",
       "      <th>x_159</th>\n",
       "      <th>x_160</th>\n",
       "      <th>x_161</th>\n",
       "      <th>x_162</th>\n",
       "      <th>x_163</th>\n",
       "      <th>x_164</th>\n",
       "      <th>x_165</th>\n",
       "      <th>x_166</th>\n",
       "      <th>x_167</th>\n",
       "      <th>x_168</th>\n",
       "      <th>x_169</th>\n",
       "      <th>x_170</th>\n",
       "      <th>x_171</th>\n",
       "      <th>x_172</th>\n",
       "      <th>x_173</th>\n",
       "      <th>x_174</th>\n",
       "      <th>x_175</th>\n",
       "      <th>x_176</th>\n",
       "      <th>x_177</th>\n",
       "      <th>x_178</th>\n",
       "      <th>x_179</th>\n",
       "      <th>x_180</th>\n",
       "      <th>x_181</th>\n",
       "      <th>x_182</th>\n",
       "      <th>x_183</th>\n",
       "      <th>x_184</th>\n",
       "      <th>x_185</th>\n",
       "      <th>x_186</th>\n",
       "      <th>x_187</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.993197</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.956916</td>\n",
       "      <td>0.902494</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.802721</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.709751</td>\n",
       "      <td>0.557823</td>\n",
       "      <td>0.321995</td>\n",
       "      <td>0.192744</td>\n",
       "      <td>0.147392</td>\n",
       "      <td>0.129252</td>\n",
       "      <td>0.099773</td>\n",
       "      <td>0.092971</td>\n",
       "      <td>0.068027</td>\n",
       "      <td>0.068027</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>0.034014</td>\n",
       "      <td>0.027211</td>\n",
       "      <td>0.013605</td>\n",
       "      <td>0.00907</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006803</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011338</td>\n",
       "      <td>0.015873</td>\n",
       "      <td>0.031746</td>\n",
       "      <td>0.054422</td>\n",
       "      <td>0.092971</td>\n",
       "      <td>0.113379</td>\n",
       "      <td>0.160998</td>\n",
       "      <td>0.185941</td>\n",
       "      <td>0.208617</td>\n",
       "      <td>0.219955</td>\n",
       "      <td>0.240363</td>\n",
       "      <td>0.231293</td>\n",
       "      <td>0.226757</td>\n",
       "      <td>0.231293</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.235828</td>\n",
       "      <td>0.235828</td>\n",
       "      <td>0.24263</td>\n",
       "      <td>0.249433</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>0.258503</td>\n",
       "      <td>0.258503</td>\n",
       "      <td>0.256236</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>0.265306</td>\n",
       "      <td>0.263039</td>\n",
       "      <td>0.272109</td>\n",
       "      <td>0.265306</td>\n",
       "      <td>0.260771</td>\n",
       "      <td>0.263039</td>\n",
       "      <td>0.267574</td>\n",
       "      <td>0.267574</td>\n",
       "      <td>0.274376</td>\n",
       "      <td>0.258503</td>\n",
       "      <td>0.265306</td>\n",
       "      <td>0.263039</td>\n",
       "      <td>0.267574</td>\n",
       "      <td>0.272109</td>\n",
       "      <td>0.263039</td>\n",
       "      <td>0.260771</td>\n",
       "      <td>0.274376</td>\n",
       "      <td>0.269841</td>\n",
       "      <td>0.274376</td>\n",
       "      <td>0.276644</td>\n",
       "      <td>0.269841</td>\n",
       "      <td>0.267574</td>\n",
       "      <td>0.274376</td>\n",
       "      <td>0.292517</td>\n",
       "      <td>0.303855</td>\n",
       "      <td>0.321995</td>\n",
       "      <td>0.337868</td>\n",
       "      <td>0.337868</td>\n",
       "      <td>0.340136</td>\n",
       "      <td>0.319728</td>\n",
       "      <td>0.297052</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.269841</td>\n",
       "      <td>0.269841</td>\n",
       "      <td>0.274376</td>\n",
       "      <td>0.269841</td>\n",
       "      <td>0.274376</td>\n",
       "      <td>0.267574</td>\n",
       "      <td>0.260771</td>\n",
       "      <td>0.371882</td>\n",
       "      <td>0.639456</td>\n",
       "      <td>0.959184</td>\n",
       "      <td>0.807256</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.29932</td>\n",
       "      <td>0.272109</td>\n",
       "      <td>0.278912</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>0.258503</td>\n",
       "      <td>0.251701</td>\n",
       "      <td>0.256236</td>\n",
       "      <td>0.247166</td>\n",
       "      <td>0.265306</td>\n",
       "      <td>0.265306</td>\n",
       "      <td>0.267574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        x_1       x_2  x_3       x_4       x_5       x_6       x_7       x_8  \\\n",
       "0  0.904762  0.993197  1.0  0.956916  0.902494  0.857143  0.802721  0.777778   \n",
       "\n",
       "        x_9      x_10      x_11      x_12      x_13      x_14      x_15  \\\n",
       "0  0.709751  0.557823  0.321995  0.192744  0.147392  0.129252  0.099773   \n",
       "\n",
       "       x_16      x_17      x_18      x_19      x_20      x_21      x_22  \\\n",
       "0  0.092971  0.068027  0.068027  0.061224  0.040816  0.034014  0.027211   \n",
       "\n",
       "       x_23     x_24  x_25      x_26  x_27      x_28      x_29      x_30  \\\n",
       "0  0.013605  0.00907   0.0  0.006803   0.0  0.011338  0.015873  0.031746   \n",
       "\n",
       "       x_31      x_32      x_33      x_34      x_35      x_36      x_37  \\\n",
       "0  0.054422  0.092971  0.113379  0.160998  0.185941  0.208617  0.219955   \n",
       "\n",
       "       x_38      x_39      x_40      x_41      x_42      x_43      x_44  \\\n",
       "0  0.240363  0.231293  0.226757  0.231293  0.238095  0.235828  0.235828   \n",
       "\n",
       "      x_45      x_46      x_47      x_48      x_49      x_50      x_51  \\\n",
       "0  0.24263  0.249433  0.253968  0.258503  0.258503  0.256236  0.253968   \n",
       "\n",
       "       x_52      x_53      x_54      x_55      x_56      x_57      x_58  \\\n",
       "0  0.265306  0.263039  0.272109  0.265306  0.260771  0.263039  0.267574   \n",
       "\n",
       "       x_59      x_60      x_61      x_62      x_63      x_64      x_65  \\\n",
       "0  0.267574  0.274376  0.258503  0.265306  0.263039  0.267574  0.272109   \n",
       "\n",
       "       x_66      x_67      x_68      x_69      x_70      x_71      x_72  \\\n",
       "0  0.263039  0.260771  0.274376  0.269841  0.274376  0.276644  0.269841   \n",
       "\n",
       "       x_73      x_74      x_75      x_76      x_77      x_78      x_79  \\\n",
       "0  0.267574  0.274376  0.292517  0.303855  0.321995  0.337868  0.337868   \n",
       "\n",
       "       x_80      x_81      x_82      x_83      x_84      x_85      x_86  \\\n",
       "0  0.340136  0.319728  0.297052  0.285714  0.269841  0.269841  0.274376   \n",
       "\n",
       "       x_87      x_88      x_89      x_90      x_91      x_92      x_93  \\\n",
       "0  0.269841  0.274376  0.267574  0.260771  0.371882  0.639456  0.959184   \n",
       "\n",
       "       x_94      x_95     x_96      x_97      x_98      x_99     x_100  \\\n",
       "0  0.807256  0.444444  0.29932  0.272109  0.278912  0.253968  0.258503   \n",
       "\n",
       "      x_101     x_102     x_103     x_104     x_105     x_106  x_107  x_108  \\\n",
       "0  0.251701  0.256236  0.247166  0.265306  0.265306  0.267574    0.0    0.0   \n",
       "\n",
       "   x_109  x_110  x_111  x_112  x_113  x_114  x_115  x_116  x_117  x_118  \\\n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "   x_119  x_120  x_121  x_122  x_123  x_124  x_125  x_126  x_127  x_128  \\\n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "   x_129  x_130  x_131  x_132  x_133  x_134  x_135  x_136  x_137  x_138  \\\n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "   x_139  x_140  x_141  x_142  x_143  x_144  x_145  x_146  x_147  x_148  \\\n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "   x_149  x_150  x_151  x_152  x_153  x_154  x_155  x_156  x_157  x_158  \\\n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "   x_159  x_160  x_161  x_162  x_163  x_164  x_165  x_166  x_167  x_168  \\\n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "   x_169  x_170  x_171  x_172  x_173  x_174  x_175  x_176  x_177  x_178  \\\n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "   x_179  x_180  x_181  x_182  x_183  x_184  x_185  x_186  x_187  \n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_patient = pd.read_csv('https://wagon-public-datasets.s3.amazonaws.com/Machine%20Learning%20Datasets/ML_Electrocardiograms_new_patient.csv')\n",
    "new_patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true,
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_knn.predict(new_patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction= \"at risk\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🧪 **Check your code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.10.6, pytest-7.1.3, pluggy-1.0.0 -- /home/parissa/.pyenv/versions/lewagon/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/parissa/code/ParissaPeimaniyfard/05-ML/03-Performance-metrics/data-electrocardiograms/tests\n",
      "plugins: typeguard-2.13.3, anyio-3.6.2, asyncio-0.19.0\n",
      "asyncio: mode=strict\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 1 item\n",
      "\n",
      "test_prediction.py::TestPrediction::test_prediction_at_risk \u001b[32mPASSED\u001b[0m\u001b[32m       [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.01s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "💯 You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/prediction.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed prediction step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('prediction',\n",
    "                         prediction = prediction)\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🏁 Congratulations!\n",
    "\n",
    "💾 Don't forget to git add/commit/push your notebook...\n",
    "\n",
    "🚀 ... and move on to the next challenge!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
